{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Data and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:58:50.157396Z",
     "start_time": "2019-04-17T19:58:47.160398Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "# download data\n",
    "df_yahoo = yf.download('AAPL', \n",
    "                       start='2000-01-01', \n",
    "                       end='2010-12-31',\n",
    "                       progress=False)\n",
    "\n",
    "print(f'Downloaded {df_yahoo.shape[0]} rows of data.')\n",
    "\n",
    "df_yahoo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from Quandl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:58:52.487386Z",
     "start_time": "2019-04-17T19:58:50.181758Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import quandl\n",
    "\n",
    "# authentication \n",
    "quandl_key = '{key}' # replace {key} with your own API key  \n",
    "quandl.ApiConfig.api_key = quandl_key\n",
    "\n",
    "# download data \n",
    "df_quandl = quandl.get(dataset='WIKI/AAPL',\n",
    "                       start_date='2000-01-01', \n",
    "                       end_date='2010-12-31')\n",
    "\n",
    "print(f'Downloaded {df_quandl.shape[0]} rows of data.')\n",
    "\n",
    "df_quandl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from IEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:58:54.125030Z",
     "start_time": "2019-04-17T19:58:52.517730Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as pdr\n",
    "\n",
    "# download data \n",
    "df_iex = pdr.DataReader(name='AAPL', \n",
    "                        data_source='iex', \n",
    "                        start='2014-01-01', \n",
    "                        end='2018-12-31')\n",
    "\n",
    "print(f'Downloaded {df_iex.shape[0]} rows of data.')\n",
    "\n",
    "df_iex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from Intrinio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:58:57.008999Z",
     "start_time": "2019-04-17T19:58:54.163967Z"
    }
   },
   "outputs": [],
   "source": [
    "import intrinio_sdk\n",
    "import pandas as pd\n",
    "\n",
    "# authentication and selecting API\n",
    "intrinio_sdk.ApiClient().configuration.api_key['api_key'] = '{key}'  # replace {key} with your own API key  \n",
    "security_api = intrinio_sdk.SecurityApi()\n",
    "\n",
    "# request data\n",
    "response = security_api.get_security_stock_prices(identifier='AAPL', \n",
    "                                                  start_date='2000-01-01',\n",
    "                                                  end_date='2010-12-31', \n",
    "                                                  frequency='daily',\n",
    "                                                  page_size=10000)\n",
    "\n",
    "# convert results into pandas DataFrame\n",
    "df_intrinio = pd.DataFrame([x.to_dict() for x in response.stock_prices]).sort_values('date')\n",
    "df_intrinio.set_index('date', inplace=True)\n",
    "\n",
    "print(f'Downloaded {df_intrinio.shape[0]} rows of data.')\n",
    "\n",
    "df_intrinio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting prices to returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:21.128352Z",
     "start_time": "2019-04-17T19:59:18.780467Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "# download data \n",
    "df = yf.download('AAPL', \n",
    "                 start='2000-01-01', \n",
    "                 end='2010-12-31',\n",
    "                 progress=False)\n",
    "\n",
    "# remove redundant data and rename column\n",
    "df = df.loc[:, ['Adj Close']]\n",
    "df.rename(columns={'Adj Close':'adj_close'}, inplace=True)\n",
    "\n",
    "# calculate simple and log returns\n",
    "df['simple_rtn'] = df.adj_close.pct_change()\n",
    "df['log_rtn'] = np.log(df.adj_close/df.adj_close.shift(1))\n",
    "\n",
    "# inspect the return series\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:22.672136Z",
     "start_time": "2019-04-17T19:59:21.804305Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "\n",
    "quandl_key = '{key}' # replace {key} with your own API key  \n",
    "quandl.ApiConfig.api_key = quandl_key\n",
    "\n",
    "df_all_dates = pd.DataFrame(index=pd.date_range(start='1999-12-31', end='2010-12-31'))\n",
    "df = df_all_dates.join(df[['adj_close']], how='left') \\\n",
    "                 .fillna(method='ffill') \\\n",
    "                 .asfreq('M')\n",
    "\n",
    "# download inflation data from Quandl\n",
    "df_cpi = quandl.get(dataset='RATEINF/CPI_USA', \n",
    "                    start_date='1999-12-01', \n",
    "                    end_date='2010-12-31')\n",
    "\n",
    "# # merge the two DataFrames\n",
    "df_merged = df.join(df_cpi, how='left')\n",
    "\n",
    "# calculate returns and inflation rate\n",
    "df_merged['simple_rtn'] = df_merged.adj_close.pct_change()\n",
    "df_merged['inflation_rate'] = df_merged.Value.pct_change()\n",
    "\n",
    "# calculate inflation-adjusted returns\n",
    "\n",
    "df_merged['real_rtn'] = (df_merged.simple_rtn + 1) / (df_merged.inflation_rate + 1) - 1\n",
    "\n",
    "# inspect results\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:24.710535Z",
     "start_time": "2019-04-17T19:59:23.359839Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "# download and clean data \n",
    "df = yf.download('AAPL', \n",
    "                 start='2000-01-01', \n",
    "                 end='2010-12-31', \n",
    "                 auto_adjust=False,\n",
    "                 progress=False)\n",
    "\n",
    "# keeping one important column and renaming\n",
    "df = df.loc[:, ['Adj Close']]\n",
    "df.rename(columns={'Adj Close': 'adj_close'}, inplace=True)\n",
    "\n",
    "# calculate simple returns\n",
    "df['simple_rtn'] = df.adj_close.pct_change()\n",
    "\n",
    "# remove redundant data\n",
    "df.drop('adj_close', axis=1, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# define function for calculating realized volatility over a group\n",
    "def realized_volatility(x):\n",
    "    return np.sqrt(np.sum(x**2))\n",
    "\n",
    "# calculate monthly realized volatility\n",
    "df_rv = df.groupby(pd.Grouper(freq='M')).apply(realized_volatility)\n",
    "\n",
    "# rename column\n",
    "df_rv.rename(columns={'simple_rtn': 'rv'}, inplace=True)\n",
    "\n",
    "# change frequency\n",
    "df_rv.rv = df_rv.rv * np.sqrt(12)\n",
    "\n",
    "# basic plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "df.plot();\n",
    "df_rv.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:26.201794Z",
     "start_time": "2019-04-17T19:59:25.422286Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "# download data as pandas DataFrame\n",
    "df = yf.download('MSFT', auto_adjust = False)\n",
    "df = df[['Adj Close']]\n",
    "df.rename(columns={'Adj Close': 'adj_close'}, inplace=True)\n",
    "\n",
    "# create simple and log returns\n",
    "df['simple_rtn'] = df.adj_close.pct_change()\n",
    "df['log_rtn'] = (np.log(df.adj_close) - np.log(df.adj_close.shift(1)))\n",
    "\n",
    "# dropping NA's in the first row\n",
    "df.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:28.227002Z",
     "start_time": "2019-04-17T19:59:26.900222Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn') #set style to `seaborn`\n",
    "\n",
    "# create placeholder subplots \n",
    "fig, ax = plt.subplots(3, 1, figsize=(24, 20))\n",
    "\n",
    "# add prices\n",
    "df.adj_close.plot(ax=ax[0])\n",
    "ax[0].set_ylabel('Stock price ($)', fontsize=14)\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].set_title('MSFT time series', fontsize=20)\n",
    "\n",
    "# add simple returns \n",
    "df.simple_rtn.plot(ax=ax[1])\n",
    "ax[1].set_ylabel('Simple returns (%)', fontsize=14)\n",
    "ax[1].set_xlabel('')\n",
    "\n",
    "# add log returns \n",
    "df.log_rtn.plot(ax=ax[2])\n",
    "ax[2].set_ylabel('Log returns (%)', fontsize=14)\n",
    "ax[2].set_xlabel('Date', fontsize=14)\n",
    "\n",
    "# display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:32.525688Z",
     "start_time": "2019-04-17T19:59:28.904032Z"
    }
   },
   "outputs": [],
   "source": [
    "import cufflinks as cf\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "# set up settings (run it once)\n",
    "#cf.set_config_file(world_readable=True, theme='pearl', offline=True)\n",
    "\n",
    "init_notebook_mode()\n",
    "\n",
    "df.iplot(subplots=True, shape=(3,1), shared_xaxes=True, title='MSFT time series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T19:59:33.947648Z",
     "start_time": "2019-04-17T19:59:33.250436Z"
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina'\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn') #set style to `seaborn`\n",
    "\n",
    "# identify outliers using 3 sigma approach ----\n",
    "\n",
    "#calculate rolling mean and standard deviation\n",
    "df_ma = df[['simple_rtn']].rolling(window=21).agg(['mean', 'std'])\n",
    "\n",
    "# drop multi-level index\n",
    "df_ma.columns = df_ma.columns.droplevel()\n",
    "\n",
    "# identify outliers\n",
    "df_outliers = df.join(df_ma)\n",
    "df_outliers['outlier'] = [1 if (x > mu + 3 * sigma) or (x < mu - 3 * sigma) else 0 for x, mu, sigma in zip(df_outliers.simple_rtn, \n",
    "                                                                                                           df_outliers['mean'], \n",
    "                                                                                                           df_outliers['std'])] \n",
    "# visualize the results ----\n",
    "\n",
    "# create instance of plot\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "# define outliers for convenience\n",
    "outliers = df_outliers.loc[df_outliers['outlier'] == 1, ['simple_rtn']]\n",
    "\n",
    "# add line plot of returns\n",
    "ax.plot(df_outliers.index, df_outliers.simple_rtn, color='blue', label='Normal')\n",
    "# add points for outliers\n",
    "ax.scatter(outliers.index, outliers.simple_rtn, color='red', label='Anomaly')\n",
    "\n",
    "# details about the plot \n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Apple stock returns', fontsize = 20)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating stylized facts of asset returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:05:59.204578Z",
     "start_time": "2019-04-17T20:05:57.894109Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import fix_yahoo_finance as yf\n",
    "\n",
    "# download and preprocess data ----\n",
    "df = yf.download('^GSPC', \n",
    "                 start='1985-01-01', \n",
    "                 end='2018-12-31',\n",
    "                 progress=False)\n",
    "\n",
    "df = df[['Adj Close']].rename(columns={'Adj Close': 'adj_close'})\n",
    "df['log_rtn'] = np.log(df.adj_close/df.adj_close.shift(1))\n",
    "df = df[['adj_close', 'log_rtn']].dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fact 1 - Non-Gaussian distribution of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:08:09.049096Z",
     "start_time": "2019-04-17T20:08:08.343435Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import fix_yahoo_finance as yf\n",
    "import seaborn as sns \n",
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "plt.style.use('seaborn') #set style to `seaborn`\n",
    "\n",
    "# plots ----\n",
    "\n",
    "# create placeholder subplots \n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "# histogram (distribution)\n",
    "sns.distplot(df.log_rtn, kde=False, norm_hist=True, ax=ax[0])                                    \n",
    "ax[0].set_title('Distribution of MSFT returns', fontsize=16)\n",
    "\n",
    "# store range of returns values\n",
    "r_range = np.linspace(min(df.log_rtn), max(df.log_rtn), num=1000)\n",
    "\n",
    "# impose a PDF of Normal distribution with sample mean and std  \n",
    "mu = df.log_rtn.mean()\n",
    "sigma = df.log_rtn.std()\n",
    "norm_pdf = scs.norm.pdf(r_range, loc=mu, scale=sigma)                                                         \n",
    "ax[0].plot(r_range, norm_pdf, 'g', lw=2, label=f'Normal({round(mu, 2)}, {round(sigma, 2)})');\n",
    "\n",
    "# add legend\n",
    "ax[0].legend();\n",
    "\n",
    "# QQ plot\n",
    "qq = sm.qqplot(df.log_rtn.values, line='s', ax=ax[1])\n",
    "ax[1].set_title('QQ plot', fontsize = 16)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics ----\n",
    "print('---------- Descriptive Statistics ----------')\n",
    "print('Range of dates:', min(df.index.date), '-', max(df.index.date))\n",
    "print('Number of observations:', df.shape[0])\n",
    "print('Mean: {0:.4f}'.format(df.log_rtn.mean()))\n",
    "print('Median: {0:.4f}'.format(df.log_rtn.median()))\n",
    "print('Min: {0:.4f}'.format(df.log_rtn.min()))\n",
    "print('Max: {0:.4f}'.format(df.log_rtn.max()))\n",
    "print('Standard Deviation: {0:.4f}'.format(df.log_rtn.std()))\n",
    "print('Skewness: {0:.4f}'.format(df.log_rtn.skew()))\n",
    "print('Kurtosis: {0:.4f}'.format(df.log_rtn.kurtosis())) \n",
    "print('Jarque-Bera statistic: {stat:.2f} with p-value: {p_val:.2f}'.format(stat = scs.jarque_bera(df.log_rtn.values)[0],\n",
    "                                                                           p_val = scs.jarque_bera(df.log_rtn.values)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fact 2 - Volatility Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:08:10.481809Z",
     "start_time": "2019-04-17T20:08:10.170501Z"
    }
   },
   "outputs": [],
   "source": [
    "df.log_rtn.plot(title='Daily MSFT returns', figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fact 3 - Absence of autocorrelation in returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:08:19.274722Z",
     "start_time": "2019-04-17T20:08:19.060296Z"
    }
   },
   "outputs": [],
   "source": [
    "# create autocorrelation plot \n",
    "acf = smt.graphics.plot_acf(df.log_rtn, lags=50 , alpha=0.05);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fact 4 - Small and decreasing autocorrelation in squared/absolute returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:08:22.696842Z",
     "start_time": "2019-04-17T20:08:22.243191Z"
    }
   },
   "outputs": [],
   "source": [
    "# specify the max amount of lags\n",
    "lags = 50\n",
    "\n",
    "# create placeholder subplots \n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# plot autocorrelation of squared returns \n",
    "smt.graphics.plot_acf(df.log_rtn ** 2, lags=lags, alpha=0.05, ax = ax[0])\n",
    "ax[0].set_ylabel('Squared Returns', fontsize=14)\n",
    "ax[0].set_title('Autocorrelation Plots', fontsize=20)\n",
    "ax[0].set_xlabel('')\n",
    "\n",
    "# plot autocorrelation of absolute returns\n",
    "smt.graphics.plot_acf(np.abs(df.log_rtn), lags=lags, alpha=0.05, ax = ax[1])\n",
    "ax[1].set_ylabel('Absolute Returns', fontsize=14)\n",
    "ax[1].set_title('')\n",
    "ax[1].set_xlabel('Lag', fontsize=14)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fact 5 - Leverage effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:11:34.163948Z",
     "start_time": "2019-04-17T20:11:32.792676Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn') #set style to `seaborn`\n",
    "\n",
    "# calculate volatility measures as moving standard deviations\n",
    "df['moving_std_252'] = df[['log_rtn']].rolling(window=252).std()\n",
    "df['moving_std_21'] = df[['log_rtn']].rolling(window=21).std()\n",
    "\n",
    "# create placeholder subplots \n",
    "fig, ax = plt.subplots(3, 1, figsize=(24, 20))\n",
    "\n",
    "# add prices\n",
    "df.adj_close.plot(ax=ax[0])\n",
    "ax[0].set_ylabel('Stock price ($)', fontsize=14)\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].set_title('MSFT time series', fontsize=20)\n",
    "\n",
    "# add simple returns \n",
    "df.log_rtn.plot(ax=ax[1])\n",
    "ax[1].set_ylabel('Log returns (%)', fontsize=14)\n",
    "ax[1].set_xlabel('')\n",
    "\n",
    "# add log returns \n",
    "df.moving_std_252.plot(ax=ax[2], color='r', label='Moving Volatility 252d')\n",
    "df.moving_std_21.plot(ax=ax[2], color='g', label='Moving Volatility 21d')\n",
    "ax[2].set_ylabel('Moving Volatility', fontsize=14)\n",
    "ax[2].set_xlabel('Date', fontsize=14)\n",
    "ax[2].legend()\n",
    "\n",
    "# display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-17T20:11:41.152000Z",
     "start_time": "2019-04-17T20:11:34.830325Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import fix_yahoo_finance as yf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn') #set style to `seaborn`\n",
    "\n",
    "# download and preprocess data ----\n",
    "df = yf.download(['^GSPC', '^VIX'], \n",
    "                 start='1985-01-01', \n",
    "                 end='2018-12-31',\n",
    "                 progress=False)\n",
    "df = df[['Adj Close']]\n",
    "df.columns = df.columns.droplevel(0)\n",
    "df = df.rename(columns={'^GSPC': 'sp500', '^VIX': 'vix'})\n",
    "df['log_rtn'] = np.log(df.sp500/df.sp500.shift(1))\n",
    "df['vol_rtn'] = np.log(df.vix/df.vix.shift(1))\n",
    "df.dropna(how='any', axis=0, inplace=True)\n",
    "\n",
    "sns.regplot(x='log_rtn', y='vol_rtn', data=df, line_kws={'color': 'red'}) \\\n",
    "   .set_title(f'SP500 returns vs. VIX returns ($\\\\rho$ = {df.log_rtn.corr(df.vol_rtn).round(2)})', fontsize=16)\n",
    "\n",
    "plt.xlabel('SP500 log returns')\n",
    "plt.ylabel('VIX log returns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "342px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
